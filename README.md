# Sephora product scraper

This repository provides a demonstration of scraping skincare product information from Sephora (https://www.sephora.com/).

The program collects product page URLs, extracts product details, and categorizes the resulting dataset.

Two scripts are used for this:

## Project Structure

```
├── sephora_scr.py           #Scrolls through several predefined categories on the Sephora website and saves the URL of every product it finds.
├── product_scr.py           #Visits each collected URL and extracts the brand, product name and ingredients.
└── data/                    #This folder contains CSV files generated by the scrapers
    ├── products_urls_full.csv  # Master list of product URLs
    ├── product_url.csv         # File used to run product_scr.py for each category
    ├── scraped_data/           #Manually made file to move into all successfully scraped data CSVs, with names changed. 
    └── skipped_links/          #Manually made file to move into files with URLs that were skipped or errored, with names changed. 
```


# How it works 

1. sephora_scr.py starts a Selenium Chrome session. For every category in the `categories` list it loads each catalog page, repeatedly scrolls until no new products appear and gathers all product links. The links are written to `data/product_urls_full.csv`. Make sure to keep your Chrome window open while running the script. 
2. Move one category from `data/product_urls_full.csv` into `data/product_data.csv`.
3. `product_scr.py` reads `data/product_urls.csv`. For each URL it loads the page, scrolls to the ingredients section and parses the HTML with BeautifulSoup. Results are saved to `data/product_data.csv` and any skipped URLs go to `data/product_skipped.csv`.
4. Change the names of the files into coreespnding category name and manually move them into scraped_data/ or skipped_links/ folders. 

File names and paths are hardcoded. If you wish to change file names then update the corresponding path in the scripts. 

Finally esnure that the data/ folder exists. 

## Setup

1. Install Python 3 and the required packages:

```bash
pip install -r requirements.txt
```

2. Install Chrome (https://www.google.com/chrome/) and the matching ChromeDriver (https://chromedriver.chromium.org/). Unzip the driver folder, and update in sephora_scr.py the chorme_path variable with the loaction of your driver. product_scr.py expects vhrome driver to be avaiable in your PATH. 


## Notes

- The scrapers rely on Selenium and may take some time to run because pages are loaded and scrolled to gather all products.
- For sephora_scr.py make sure to keep Chrome window open and visiable for best scarping results.
- Follow the given organisation of files for best results. 